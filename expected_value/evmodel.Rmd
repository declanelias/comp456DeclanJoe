---
title: "EV Model"
output: html_document
date: '2022-11-16'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidymodels)
library(tidyverse)
```



```{r}
get_brier_score = function(df) {
  brier_data = df %>%
    group_by(book_id) %>%
    summarise(brier_score = mean(brier_score),
              n = n())
  
  brier_ref = (brier_data %>%
    filter(book_id != 5000) %>%
    summarise(brier_score = mean(brier_score)))$brier_score
  
  get_brier_ss = function(brier_score) {
    return(1 -  brier_score / brier_ref)
  }
    
  
  brier_data = brier_data %>%
    group_by(book_id) %>%
    mutate(brier_skill_score = get_brier_ss(brier_score)) %>% 
    ungroup()
  
  return(brier_data)
}
```

# College Football

```{r warning=FALSE}
source("clean_data.R")
source("book_average.R")

ncaaf_raw = clean_data("ncaaf")
ncaaf_ml = average_books(ncaaf_raw)

save(ncaaf_ml, file = "betting_data/ncaaf_ml_clean.rdata")

load("betting_data/ncaaf_ml_clean.rdata")
```

## Clean Data

```{r}
ncaaf_ml = ncaaf_ml %>%
  filter(!is.na(parent_name))

ncaaf_ml = ncaaf_ml %>%
  filter(!(parent_name %in% c("Consensus", "Open")))


# Only get the books with 150+ observations every year from 2018-2022
ncaaf_ml = ncaaf_ml %>%
  filter(season > 2018) %>%
  group_by(season, parent_name) %>%
  filter(n() >= 150) %>%
  ungroup(season) %>%
  filter(all(2019:2022 %in% season)) %>%
  ungroup()

# Only get games that have a line for each observation

ncaaf_ml = ncaaf_ml %>%
  group_by(id) %>%
  filter(all(ncaaf_ml$parent_name %>% unique() %in% parent_name)) %>%
  ungroup()
```


## First Test: Using the Brier Score as a weighted average

#### Create the Testing and Training Sets
```{r}
test_data_wa = ncaaf_ml %>%
  filter(season == 2022)

train_data_wa = ncaaf_ml %>%
  filter(season != 2022)
```

#### Train the data

```{r}
brier_train_data = get_brier_score(train_data_wa)

brier_train_data = brier_train_data %>%
  filter(brier_skill_score > 0)
```

#### Apply it to the Test data

```{r}

get_brier_ss_of_book = function(this.book_id) {

  if (this.book_id %in% brier_train_data$book_id) {
    row = brier_train_data %>%
      filter(book_id == this.book_id)
    return(row$brier_skill_score)
  }
  return(0)
}

calc_weight_sum = function(book_id_list) {
  return(sum(map_dbl(book_id_list, get_brier_ss_of_book)))
}


calc_weighted_win_prob = function(book_id, win_prob) {
  
  brier_ss = map_dbl(book_id, get_brier_ss_of_book)
  
  return(brier_ss * win_prob)
}


model_data = test_data_wa %>%
  mutate(weighted_home_prob_fair = calc_weighted_win_prob(book_id, home_prob_fair))


model_data = model_data %>%
  group_by(id) %>%
  summarise(id = mean(id),
            home_team_win = first(home_team_win),
            home_prob_fair = sum(weighted_home_prob_fair) / calc_weight_sum(book_id),
            away_prob_fair = 1 - home_prob_fair)

model_data = model_data %>%
  mutate(parent_name = "weighted_average",
         league = "ncaaf",
         season = 2022,
         book_id = 5000,
         brier_score = (home_prob_fair - home_team_win) ^ 2,
         home_prob_vig = NA,
         away_prob_vig = NA,
         ml_home = NA,
         ml_away = NA)

test_data_wa = rbind(test_data_wa, model_data)

get_brier_score(test_data_wa)

save(test_data_wa, file = "model_data/test_data_wa_ncaaf.rdata")
```

```{r}
weighted_average_output = test_data_wa %>%
  select(-c(brier_score, away_prob_fair, home_prob_vig, away_prob_vig, ml_home, ml_away, book_id)) %>%
  pivot_wider(names_from = parent_name, values_from = home_prob_fair) %>%
  mutate(home_team_win = as.factor(as.integer(home_team_win)))

weighted_average_output = weighted_average_output %>%
  mutate(.pred_win = make_two_class_pred(1 - weighted_average, levels(home_team_win), threshold = .5))

weighted_average_output %>%
  conf_mat(truth = home_team_win, estimate = .pred_win)

sens = 80 / (80 + 24)
spec = 65 / (65 + 18)
accuracy= (80 + 65) / (80 + 24 + 65 + 18)

metric = c("sens", "spec", "accuracy")
value = c(sens, spec, accuracy)

as.data.frame(cbind(metric, value))
```




## Ev calculation


```{r}
get_model_implied_prob = function(list_id, implied_prob) {
  implied_prob[which(list_id == 5000)]
}

calc_ev = function(implied_win, implied_loss, ml_win, stake) {
  profit = if_else(ml_win < 0, 100 / abs(ml_win) * stake, ml_win)
  
  return(implied_win * profit - implied_loss * stake)
}

ev_data = test_data_wa %>%
  group_by(id) %>%
  mutate(model_home_fair = get_model_implied_prob(book_id, home_prob_fair),
         model_away_fair = get_model_implied_prob(book_id, away_prob_fair),
         ev_home =  calc_ev(model_home_fair, model_away_fair, ml_home, 100),
         ev_away = calc_ev(model_away_fair, model_home_fair, ml_away, 100))
```

# Logistic Regression

```{r}
library(tidymodels)
library(probably)
```

```{r}
logreg_ncaaf = ncaaf_ml %>%
  select(-c(brier_score, away_prob_fair, home_prob_vig, away_prob_vig, ml_home, ml_away, book_id)) %>%
  pivot_wider(names_from = parent_name, values_from = home_prob_fair) %>%
  mutate(home_team_win = as.factor(as.integer(home_team_win)))

logreg_train = logreg_ncaaf %>%
  filter(season != 2022) %>%
  select(-c(id, season, league))

logreg_test = logreg_ncaaf %>%
  filter(season == 2022) %>%
  select(-c(id, season, league))

logistic_spec = logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")

logistic_rec = recipe(home_team_win ~ ., data = logreg_train)

log_wf = workflow() %>%
  add_recipe(logistic_rec) %>%
  add_model(logistic_spec)

log_fit = fit(log_wf, data = logreg_train)
```

```{r}
log_fit %>% tidy()

log_fit %>% 
  tidy() %>%
  mutate(OR.conf.low = exp(estimate - 1.96*std.error), OR.conf.high = exp(estimate + 1.96*std.error)) %>% # do this first
  mutate(OR = exp(estimate))
```


```{r}
logistic_output = logreg_test %>%
  bind_cols(predict(log_fit, new_data = logreg_test, type = 'prob'))

logistic_output <- logistic_output %>%
  mutate(.pred_win = make_two_class_pred(.pred_0, levels(home_team_win), threshold = .5))

logistic_output  %>%
  conf_mat(truth = home_team_win, estimate = .pred_win)

log_metrics <- metric_set(yardstick::sens, yardstick::spec, yardstick::accuracy)

logistic_output %>% 
  log_metrics(estimate = .pred_win, truth = home_team_win, event_level = "second")
```


```{r}
brier_score = mean((logistic_output$.pred_1 - (as.numeric(logistic_output$home_team_win) - 1)) ^ 2)
brie_ss = get_brier_ss_of_book(brier_score)
```

